{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mydl-ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neilsen1994/AutoDL_Project/blob/master/Mydl_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB_fb8CIATNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "07f9784f-8ec9-49f1-ede0-50548da73c88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/data\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "classes_names.txt  test_img.txt    train_img\t  train_label.txt\n",
            "test_img\t   test_label.txt  train_img.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSMe4hxv0dbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCCEbRlG_vtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class DatasetProcessing(Dataset):\n",
        "    def __init__(self, data_path, img_path, img_filename, label_filename, transform=None):\n",
        "        self.img_path = os.path.join(data_path, img_path)\n",
        "        self.transform = transform\n",
        "        # reading img file from file\n",
        "        img_filepath = os.path.join(data_path, img_filename)\n",
        "        fp = open(img_filepath, 'r')\n",
        "        self.img_filename = [x.strip() for x in fp]\n",
        "        fp.close()\n",
        "        # reading labels from file\n",
        "        label_filepath = os.path.join(data_path, label_filename)\n",
        "        labels = np.loadtxt(label_filepath, dtype=np.int64)\n",
        "        self.label = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(os.path.join(self.img_path, self.img_filename[index]))\n",
        "        img = img.convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        label = torch.from_numpy(self.label[index])\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.img_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dkGIkjv_0N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bUB9nMh_7DB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "60b4a243-758a-4b77-b746-151636d4fa63"
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/data'\n",
        "TRAIN_DATA = 'train_img'\n",
        "TEST_DATA = 'test_img'\n",
        "TRAIN_IMG_FILE = 'train_img.txt'\n",
        "TEST_IMG_FILE = 'test_img.txt'\n",
        "TRAIN_LABEL_FILE = 'train_label.txt'\n",
        "TEST_LABEL_FILE = 'test_label.txt'\n",
        "\n",
        "NLABELS = 5\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Scale(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()])\n",
        "dset_train = DatasetProcessing(\n",
        "    DATA_PATH, TRAIN_DATA, TRAIN_IMG_FILE, TRAIN_LABEL_FILE, transformations)\n",
        "\n",
        "dset_test = DatasetProcessing(\n",
        "    DATA_PATH, TEST_DATA, TEST_IMG_FILE, TEST_LABEL_FILE, transformations)\n",
        "\n",
        "train_loader = DataLoader(dset_train,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4\n",
        "                         )\n",
        "\n",
        "test_loader = DataLoader(dset_test,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False,\n",
        "                         num_workers=4\n",
        "                         )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKKm8kAT0kRm",
        "colab_type": "code",
        "outputId": "be69b749-f6e4-4248-e8a2-3cc322f17e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "batch_size = 10\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "x_train = torch.from_numpy(pickle.load(open(\"./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/X_train.pkl\", \"rb\"))).permute(0,3,1,2).type('torch.FloatTensor')\n",
        "y_train = torch.from_numpy(pickle.load(open(\"./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/y_train.pkl\", \"rb\"))).type('torch.LongTensor')\n",
        "train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "\n",
        "x_test = torch.from_numpy(pickle.load(open(\"./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/X_test.pkl\", \"rb\"))).permute(0,3,1,2).type('torch.FloatTensor')\n",
        "y_test = torch.from_numpy(pickle.load(open(\"./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/y_test.pkl\", \"rb\"))).type('torch.LongTensor')\n",
        "test_set = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "train_sampler = torch.utils.data.SequentialSampler(train_set)\n",
        "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2) \n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, sampler=test_sampler, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzn0-uze0t07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    \n",
        "    #Loss function\n",
        "    loss = torch.nn.BCELoss()\n",
        "    \n",
        "    #Optimizer\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return(loss, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrlyKGHskTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py (17.05.2019)\n",
        "\n",
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1 # for increasing the number of output filters for the last layer\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(25088*block.expansion, 5)\n",
        "        \n",
        "        #self.linear = nn.Linear(512*block.expansion, 2)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        print(strides)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        #print('-----------',out.shape)#([4, 512, 50, 50])\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        #print('-------------------',out.shape)#torch.Size([4, 512, 12, 12])\n",
        "        out = out.view(out.size(0), -1)#512*12*12 = 73728\n",
        "        out = self.linear(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [1,1,1,1])\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swSxw5R30unK",
        "colab_type": "code",
        "outputId": "6d6b991e-b32b-4522-ebd4-951a9c27b96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "source": [
        "\n",
        "predictions = []\n",
        "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
        "    \n",
        "    #Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    n_batches = len(train_loader)\n",
        "    \n",
        "    #Create our loss and optimizer functions\n",
        "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    \n",
        "    #Time for printing\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    #Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = n_batches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            \n",
        "            #Get inputs\n",
        "            inputs, labels = data\n",
        "            \n",
        "            #Wrap them in a Variable object\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            print(\"Input shape\",inputs.shape)\n",
        "            labels = labels.to(dtype=torch.float)\n",
        "            #print(labels.shape)\n",
        "            #Set the parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            #print('the type of the lables',labels.dtype)\n",
        "            #print('the type of the outputs',outputs.dtype)\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            #print(loss_size.item())\n",
        "            #Print statistics\n",
        "            running_loss += loss_size.item()\n",
        "            total_train_loss += loss_size.item()\n",
        "            \n",
        "            #Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, Batch_no {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                        epoch+1, i ,int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                #Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            \n",
        "        #At the end of the epoch, do a pass on the test set\n",
        "        total_test_loss = 0\n",
        "        \n",
        "        for inputs, labels in test_loader:\n",
        "            \n",
        "            #Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            labels = labels.to(dtype=torch.float)\n",
        "            #print(inputs.shape)\n",
        "            #print(labels.shape)\n",
        "            #Forward pass\n",
        "            test_outputs = net(inputs)\n",
        "            predictions.append(test_outputs)\n",
        "            test_loss_size = loss(test_outputs, labels)\n",
        "            total_test_loss += test_loss_size.item()\n",
        "            \n",
        "        print(\"Validation loss = {:.2f}\".format(total_test_loss / len(test_loader)))\n",
        "        \n",
        "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
        "    \n",
        "\n",
        "network = ResNet18()\n",
        "print(network)\n",
        "trainNet(network, batch_size=batch_size, n_epochs=1, learning_rate=0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[2]\n",
            "[2]\n",
            "[2]\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=25088, out_features=5, bias=True)\n",
            ")\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 32\n",
            "epochs= 1\n",
            "learning_rate= 0.0001\n",
            "==============================\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 4, 10% \t train_loss: 0.70 took: 298.95s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 9, 21% \t train_loss: 0.55 took: 281.99s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 14, 31% \t train_loss: 0.53 took: 274.57s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 19, 42% \t train_loss: 0.52 took: 273.56s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 24, 53% \t train_loss: 0.53 took: 274.31s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Epoch 1, Batch_no 29, 63% \t train_loss: 0.47 took: 274.17s\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n",
            "Input shape torch.Size([32, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}