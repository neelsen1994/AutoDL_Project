# -*- coding: utf-8 -*-
"""Mydl-ResNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_J_uerRqvmVUL3WtRrwq1YHwGeuCUu5q
"""

from google.colab import drive
drive.mount('/content/drive')
!ls "/content/drive/My Drive/data"

import numpy as np
import torch
from torch.autograd import Variable
import torch.nn.functional as F
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import pickle
import time
from google.colab import drive

import os
from PIL import Image
from torch.utils.data.dataset import Dataset
import numpy as np

class DatasetProcessing(Dataset):
    def __init__(self, data_path, img_path, img_filename, label_filename, transform=None):
        self.img_path = os.path.join(data_path, img_path)
        self.transform = transform
        # reading img file from file
        img_filepath = os.path.join(data_path, img_filename)
        fp = open(img_filepath, 'r')
        self.img_filename = [x.strip() for x in fp]
        fp.close()
        # reading labels from file
        label_filepath = os.path.join(data_path, label_filename)
        labels = np.loadtxt(label_filepath, dtype=np.int64)
        self.label = labels

    def __getitem__(self, index):
        img = Image.open(os.path.join(self.img_path, self.img_filename[index]))
        img = img.convert('RGB')
        if self.transform is not None:
            img = self.transform(img)
        label = torch.from_numpy(self.label[index])
        return img, label
    def __len__(self):
        return len(self.img_filename)

from torchvision import transforms
import torch.nn as nn
from torch.utils.data import DataLoader
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
import torch

DATA_PATH = '/content/drive/My Drive/data'
TRAIN_DATA = 'train_img'
TEST_DATA = 'test_img'
TRAIN_IMG_FILE = 'train_img.txt'
TEST_IMG_FILE = 'test_img.txt'
TRAIN_LABEL_FILE = 'train_label.txt'
TEST_LABEL_FILE = 'test_label.txt'

NLABELS = 5

batch_size = 32

transformations = transforms.Compose([
    transforms.Scale(256),
    transforms.CenterCrop(224),
    transforms.ToTensor()])
dset_train = DatasetProcessing(
    DATA_PATH, TRAIN_DATA, TRAIN_IMG_FILE, TRAIN_LABEL_FILE, transformations)

dset_test = DatasetProcessing(
    DATA_PATH, TEST_DATA, TEST_IMG_FILE, TEST_LABEL_FILE, transformations)

train_loader = DataLoader(dset_train,
                          batch_size=batch_size,
                          shuffle=True,
                          num_workers=4
                         )

test_loader = DataLoader(dset_test,
                         batch_size=batch_size,
                         shuffle=False,
                         num_workers=4
                         )

batch_size = 10

drive.mount('/content/drive')
x_train = torch.from_numpy(pickle.load(open("./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/X_train.pkl", "rb"))).permute(0,3,1,2).type('torch.FloatTensor')
y_train = torch.from_numpy(pickle.load(open("./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/y_train.pkl", "rb"))).type('torch.LongTensor')
train_set = torch.utils.data.TensorDataset(x_train, y_train)

x_test = torch.from_numpy(pickle.load(open("./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/X_test.pkl", "rb"))).permute(0,3,1,2).type('torch.FloatTensor')
y_test = torch.from_numpy(pickle.load(open("./drive/My Drive/multilabel_poster/Multi_Label_dataset/pickle_1000/y_test.pkl", "rb"))).type('torch.LongTensor')
test_set = torch.utils.data.TensorDataset(x_test, y_test)

train_sampler = torch.utils.data.SequentialSampler(train_set)
test_sampler = torch.utils.data.SequentialSampler(test_set)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2) 
test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, sampler=test_sampler, num_workers=2)

def createLossAndOptimizer(net, learning_rate=0.001):
    
    #Loss function
    loss = torch.nn.BCELoss()
    
    #Optimizer
    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)
    
    return(loss, optimizer)

# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py (17.05.2019)

'''ResNet in PyTorch.

For Pre-activation ResNet, see 'preact_resnet.py'.

Reference:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
    Deep Residual Learning for Image Recognition. arXiv:1512.03385
'''
import torch
import torch.nn as nn
import torch.nn.functional as F


class BasicBlock(nn.Module):
    expansion = 1 # for increasing the number of output filters for the last layer

    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion*planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion*planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out



class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.linear = nn.Linear(25088*block.expansion, 5)
        
        #self.linear = nn.Linear(512*block.expansion, 2)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1)
        print(strides)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        #print('-----------',out.shape)#([4, 512, 50, 50])
        out = F.avg_pool2d(out, 4)
        #print('-------------------',out.shape)#torch.Size([4, 512, 12, 12])
        out = out.view(out.size(0), -1)#512*12*12 = 73728
        out = self.linear(out)
        out = torch.sigmoid(out)
        return out


def ResNet18():
    return ResNet(BasicBlock, [1,1,1,1])

predictions = []
def trainNet(net, batch_size, n_epochs, learning_rate):
    
    #Print all of the hyperparameters of the training iteration:
    print("===== HYPERPARAMETERS =====")
    print("batch_size=", batch_size)
    print("epochs=", n_epochs)
    print("learning_rate=", learning_rate)
    print("=" * 30)
    
    n_batches = len(train_loader)
    
    #Create our loss and optimizer functions
    loss, optimizer = createLossAndOptimizer(net, learning_rate)
    
    #Time for printing
    training_start_time = time.time()
    
    #Loop for n_epochs
    for epoch in range(n_epochs):
        
        running_loss = 0.0
        print_every = n_batches // 10
        start_time = time.time()
        total_train_loss = 0
        
        for i, data in enumerate(train_loader, 0):
            
            #Get inputs
            inputs, labels = data
            
            #Wrap them in a Variable object
            inputs, labels = Variable(inputs), Variable(labels)
            print("Input shape",inputs.shape)
            labels = labels.to(dtype=torch.float)
            #print(labels.shape)
            #Set the parameter gradients to zero
            optimizer.zero_grad()
            
            #Forward pass, backward pass, optimize
            outputs = net(inputs)
            #print('the type of the lables',labels.dtype)
            #print('the type of the outputs',outputs.dtype)
            loss_size = loss(outputs, labels)
            loss_size.backward()
            optimizer.step()
            #print(loss_size.item())
            #Print statistics
            running_loss += loss_size.item()
            total_train_loss += loss_size.item()
            
            #Print every 10th batch of an epoch
            if (i + 1) % (print_every + 1) == 0:
                print("Epoch {}, Batch_no {}, {:d}% \t train_loss: {:.2f} took: {:.2f}s".format(
                        epoch+1, i ,int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))
                #Reset running loss and time
                running_loss = 0.0
                start_time = time.time()
            
        #At the end of the epoch, do a pass on the test set
        total_test_loss = 0
        
        for inputs, labels in test_loader:
            
            #Wrap tensors in Variables
            inputs, labels = Variable(inputs), Variable(labels)
            labels = labels.to(dtype=torch.float)
            #print(inputs.shape)
            #print(labels.shape)
            #Forward pass
            test_outputs = net(inputs)
            predictions.append(test_outputs)
            test_loss_size = loss(test_outputs, labels)
            total_test_loss += test_loss_size.item()
            
        print("Validation loss = {:.2f}".format(total_test_loss / len(test_loader)))
        
    print("Training finished, took {:.2f}s".format(time.time() - training_start_time))
    

network = ResNet18()
print(network)
trainNet(network, batch_size=batch_size, n_epochs=1, learning_rate=0.0001)